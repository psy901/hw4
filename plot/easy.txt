The data below shows the number of steps/actions the agent required to reach 
the terminal state given the number of iterations the algorithm was run.
Iterations,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100
Value Iteration,44,10,9,8,10,9,9,10,13,10,7,9,8,12,10,8,8,8,9,7,7,9,9,11,9,12,8,10,8,9,13,12,9,7,7,7,8,10,7,11,9,11,7,10,9,8,9,9,10,12,11,10,7,7,14,9,7,7,7,9,9,10,12,9,7,7,8,10,8,7,7,11,9,7,14,10,12,10,7,15,11,12,8,7,10,7,13,7,8,7,7,8,9,9,7,9,9,9,7,7
Policy Iteration,116,8,9,7,11,8,7,7,7,7,13,7,9,8,9,8,11,7,7,9,8,13,9,12,15,9,14,11,12,9,14,8,7,7,7,9,10,9,9,10,12,7,7,7,10,7,8,9,7,7,10,7,8,7,9,7,9,8,9,11,8,13,10,13,13,7,7,8,10,10,12,13,7,9,8,7,12,8,9,8,12,11,7,7,11,10,10,10,8,7,8,7,11,7,11,10,8,10,7,7
Q Learning,63,32,8,16,20,18,17,12,8,9,11,12,10,18,31,18,12,14,13,100,8,12,9,7,12,12,64,9,20,9,10,7,8,45,17,53,7,9,9,8,8,11,10,21,31,13,15,13,12,7,12,7,51,40,9,14,333,17,9,11,11,11,8,8,16,12,13,8,16,9,35,37,8,8,32,21,34,13,7,18,14,9,13,7,7,9,48,12,13,33,12,16,15,7,9,7,10,13,9,10

The data below shows the number of milliseconds the algorithm required to generate 
the optimal policy given the number of iterations the algorithm was run.
Iterations,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100
Value Iteration,18,4,4,5,11,3,3,3,3,3,2,2,3,7,2,3,3,3,3,3,3,6,6,6,7,8,6,5,4,4,4,5,4,5,5,9,11,11,10,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,11,11,12,11,12,9,5,5,5,5,6,6,6,6,6,5,5,5,6,5,6,6,6,7,6,6,7,6,7,7,9,8,7,7,7,7,7,7,7
Policy Iteration,2,0,3,1,1,2,2,2,3,3,3,3,3,3,3,4,3,4,3,4,5,4,5,4,5,5,5,5,6,8,6,6,7,6,7,7,7,7,7,7,7,8,8,8,9,8,8,8,8,10,8,9,9,10,10,10,10,10,10,10,10,11,11,13,11,11,12,12,12,12,12,12,12,12,13,11,12,12,12,12,12,12,12,11,13,11,12,12,12,12,13,14,15,15,14,13,13,14,14,14
Q Learning,7,0,0,1,1,1,1,0,1,0,0,0,0,0,3,0,0,1,1,5,1,0,1,1,1,1,2,1,1,1,1,1,5,2,3,2,2,1,1,1,1,1,1,1,2,1,3,2,2,3,1,3,3,4,3,4,7,2,2,2,3,1,2,2,2,5,2,2,3,5,2,5,2,5,3,2,4,3,3,6,4,3,4,3,9,4,3,10,6,2,5,4,4,4,3,7,4,9,5,7

The data below shows the total reward gained for 
the optimal policy given the number of iterations the algorithm was run.
Iterations,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100
Value Iteration Rewards,95.8,99.2,99.3,99.4,99.2,99.3,99.3,99.2,98.9,99.2,99.5,99.3,99.4,99.0,99.2,99.4,99.4,99.4,99.3,99.5,99.5,-0.5999999999999943,99.3,-0.799999999999983,99.3,99.0,99.4,99.2,99.4,99.3,98.9,99.0,99.3,99.5,99.5,99.5,99.4,99.2,99.5,99.1,99.3,99.1,99.5,99.2,99.3,99.4,99.3,99.3,99.2,99.0,99.1,99.2,99.5,99.5,98.8,99.3,99.5,99.5,99.5,99.3,99.3,99.2,99.0,99.3,99.5,99.5,99.4,99.2,99.4,99.5,99.5,99.1,99.3,99.5,98.8,99.2,99.0,99.2,99.5,98.7,99.1,99.0,99.4,99.5,99.2,99.5,98.9,99.5,99.4,99.5,99.5,99.4,99.3,99.3,99.5,99.3,99.3,99.3,99.5,99.5
Policy Iteration Rewards,88.60000000000002,99.4,99.3,99.5,99.1,99.4,99.5,99.5,99.5,99.5,98.9,99.5,99.3,99.4,99.3,99.4,99.1,99.5,99.5,99.3,99.4,98.9,99.3,99.0,98.7,99.3,98.8,99.1,99.0,99.3,98.8,99.4,99.5,99.5,99.5,99.3,99.2,99.3,99.3,99.2,99.0,99.5,99.5,99.5,99.2,99.5,99.4,99.3,99.5,99.5,99.2,99.5,99.4,99.5,99.3,99.5,99.3,99.4,99.3,99.1,99.4,98.9,99.2,-0.9999999999999716,98.9,99.5,99.5,99.4,99.2,99.2,99.0,98.9,99.5,99.3,99.4,99.5,99.0,99.4,99.3,99.4,99.0,99.1,99.5,99.5,99.1,99.2,99.2,99.2,99.4,99.5,99.4,99.5,99.1,99.5,99.1,99.2,99.4,99.2,99.5,99.5
Q Learning Rewards,-105.89999999999986,97.0,-0.5,98.6,-1.6999999999999886,98.4,98.5,99.0,99.4,99.3,99.1,-0.9000000000000057,99.2,98.4,-102.69999999999999,-1.4999999999999432,99.0,98.8,98.9,-9.699999999999733,99.4,99.0,99.3,99.5,99.0,99.0,-6.099999999999994,99.3,98.2,99.3,99.2,99.5,99.4,95.7,98.5,-5.0,99.5,99.3,99.3,99.4,99.4,99.1,99.2,98.1,97.1,98.9,98.7,98.9,99.0,99.5,99.0,99.5,95.1,96.2,99.3,98.8,66.8999999999998,98.5,99.3,99.1,99.1,99.1,99.4,99.4,98.6,99.0,98.9,99.4,98.6,99.3,96.7,96.5,99.4,-0.5,-202.69999999999993,98.1,96.8,98.9,99.5,-1.5,-1.0999999999999943,99.3,98.9,99.5,99.5,99.3,95.4,99.0,98.9,96.9,99.0,98.6,98.7,99.5,99.3,99.5,99.2,98.9,99.3,99.2
